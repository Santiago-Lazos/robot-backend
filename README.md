# ğŸ¤– Backend â€“ Intercarreras

API desarrollada en **Node.js + Express**.

**Prototipo de Montacargas AutÃ³nomo** del trabajo **Intercarreras 2025**.

Esta API actÃºa como el **nÃºcleo de comunicaciÃ³n** entre el **Bridge** (microservicio intermedio que se comunica con el robot vÃ­a MQTT) y el resto de los mÃ³dulos del sistema, el frontend (control remoto y panel administrativo).

---

## ğŸ¯ Objetivo

Centralizar el flujo de datos entre los servicios del robot:

- ğŸ” Recibir datos del **Bridge**, provenientes del robot.
- ğŸ›°ï¸ Enviar **Ã³rdenes de movimiento y tareas** al robot, a travÃ©s del **Bridge**.
- ğŸ§  Guardar datos en **MongoDB Atlas** y **Cloudflare R2**.
- ğŸ“¡ Notificar eventos en tiempo real a travÃ©s de **SSE**.
- ğŸ“¦ Suministrar datos a travÃ©s de **API REST** al **control remoto** y **panel administrativo**.

---

## ğŸ§± Estructura del Proyecto

```
robot-backend/
â”œâ”€ src/
â”‚ â”œâ”€ models/
â”‚ â”‚ â””â”€ Image.js â†’ Esquema de imÃ¡genes en MongoDB Atlas
â”‚ â”‚
â”‚ â”œâ”€ routes/
â”‚ â”‚ â”œâ”€ commands.routes.js â†’ /api/robot/command â†’ EnvÃ­o de comandos al robot
â”‚ â”‚ â”œâ”€ sensors.routes.js â†’ /api/sensors/data â†’ Lectura de sensores
â”‚ â”‚ â”œâ”€ status.routes.js â†’ /api/status â†’ Estado general del robot
â”‚ â”‚ â”œâ”€ images.routes.js â†’ /api/images â†’ Registro, anÃ¡lisis y consulta de imÃ¡genes
â”‚ â”‚ â”œâ”€ webhook.routes.js â†’ /api/webhook â†’ RecepciÃ³n de datos desde el Bridge
â”‚ â”‚ â””â”€ stream.routes.js â†’ /api/stream â†’ Eventos SSE en tiempo real
â”‚ â”‚
â”‚ â”œâ”€ utils/
â”‚ â”‚ â”œâ”€ messageHandlers/ â†’ Funciones que manejan los tipos de mensajes entrantes
â”‚ â”‚ â”‚ â”œâ”€ handleAck.js â†’ Procesa confirmaciones (ACK)
â”‚ â”‚ â”‚ â”œâ”€ handleConnected.js â†’ Procesa conexiÃ³n del robot
â”‚ â”‚ â”‚ â”œâ”€ handleDisconnected.js â†’ Procesa desconexiÃ³n del robot
â”‚ â”‚ â”‚ â”œâ”€ handleError.js â†’ Procesa errores del robot
â”‚ â”‚ â”‚ â”œâ”€ handleUnknown.js â†’ Captura tipos de mensajes no reconocidos
â”‚ â”‚ â”‚ â””â”€ index.js â†’ Exporta y organiza los handlers
â”‚ â”‚ â”œâ”€ analyzeImageWithAI.js â†’ AnÃ¡lisis de imÃ¡genes con OpenAI
â”‚ â”‚ â”œâ”€ decodeQRFromBuffer.js â†’ DecodificaciÃ³n de QR desde buffer
â”‚ â”‚ â”œâ”€ handleSign.js â†’ Procesa seÃ±ales (Ã³rdenes) del robot
â”‚ â”‚ â”œâ”€ upload.js â†’ Subida de imÃ¡genes
â”‚ â”‚ â””â”€ sendCommand.js â†’ EnvÃ­o de comandos al robot
â”‚ â”‚
â”‚ â”œâ”€ config.js â†’ ConfiguraciÃ³n general y variables de entorno
â”‚ â””â”€ server.js â†’ Servidor principal Express y conexiÃ³n a MongoDB
â”‚
â”œâ”€ .env.example â†’ Ejemplo de variables de entorno necesarias
â”œâ”€ package.json â†’ Dependencias del proyecto
â”œâ”€ package-lock.json â†’ VersiÃ³n bloqueada de dependencias
â””â”€ README.md â†’ DocumentaciÃ³n tÃ©cnica de la API
```

---

## âš™ï¸ InstalaciÃ³n y EjecuciÃ³n

### 1ï¸âƒ£ Clonar el repositorio

```bash
git clone https://github.com/Santiago-Lazos/robot-backend.git
cd robot-backend
```

### 2ï¸âƒ£ Instalar

```bash
npm install
```

### 3ï¸âƒ£ Crear el archivo .env

```bash
cp .env.example .env
```

### 4ï¸âƒ£ Iniciar el servidor

```bash
npm run dev
```

---

### Desarrollo local de API

La API quedarÃ¡ disponible para desarrollo local en:

ğŸ”— http://localhost:3000

### ğŸŒ API en producciÃ³n

La API estÃ¡ desplegada en Render: [https://robot-backend-6o4d.onrender.com](https://robot-backend-6o4d.onrender.com)

### ğŸŒ Endpoints Principales (API REST)

#### ğŸš€ Comandos

- POST `/api/robot/command` â†’ EnvÃ­a un comando al robot a travÃ©s del **Bridge**.

Body de ejemplo:

```json
{
  "robotId": "68faa22f17d51b1089c1f1d5",
  "commandType": "move",
  "content": {
    "direction": "forward"
  }
}
```

#### ğŸ“¡ Sensores

- POST `/api/sensors/data` â†’ Recibe lecturas del sensor ultrasÃ³nico o similares.

#### âš™ï¸ Estado del Robot

- GET `/api/status` â†’ Devuelve el Ãºltimo estado conocido del robot.
- POST `/api/status/update` â†’ Actualiza el estado (para pruebas locales).
- GET `/api/status/stream` â†’ EnvÃ­o en tiempo real (SSE).

#### ğŸ–¼ï¸ ImÃ¡genes

- POST `/api/images/upload` â†’ Sube una imagen a Cloudflare R2 y registra en MongoDB. Espera un archivo en el campo `image` (multipart/form-data).
- GET `/api/images` â†’ Lista todas las imÃ¡genes registradas en MongoDB.
- GET `/api/images/:id` â†’ Obtiene una imagen por su ObjectID de MongoDB.
- POST `/api/images/scan-qr` â†’ Escanea un QR desde una imagen subida por multipart/form-data.
- POST `/api/images/scan-qr/url` â†’ Escanea un QR desde una URL.
- POST `/api/images/scan-qr/base64` â†’ Escanea un QR desde una base64.
- POST `/api/images/ai-analyze` â†’ Analiza una imagen con IA.

#### ğŸŒ Webhook

- POST `/api/webhook` â†’ Recibe datos desde el Bridge (por ejemplo, imÃ¡genes o lecturas).

---

### ğŸ§  Esquema de Base de Datos

Modelo `Image`:

```json
{
  robotId: String,
  url: String,
  type: String,
  description: String,
  timestamp: Date
}
```

---

### ğŸ“¡ Eventos SSE (Server-Sent Events)

El backend implementa **Server-Sent Events (SSE)** para notificar en tiempo real al frontend sobre eventos importantes sin necesidad de hacer peticiones constantes.

El endpoint del stream es: `/api/stream`

| Evento               | DescripciÃ³n                                                  | Data enviada                            |
| -------------------- | ------------------------------------------------------------ | --------------------------------------- |
| `new_image`          | Se dispara cuando el robot envÃ­a una nueva imagen procesada. | `{ id, timestamp }`                     |
| `ack_received`       | ConfirmaciÃ³n de que el robot recibiÃ³ o completÃ³ una acciÃ³n.  | `{ type, action, state, timestamp }`    |
| `robot_connected`    | Indica que el robot se ha conectado correctamente.           | `{ status: "connected", timestamp }`    |
| `robot_disconnected` | Indica que el robot se ha desconectado.                      | `{ status: "disconnected", timestamp }` |
| `robot_error`        | Se dispara cuando el robot informa un error.                 | `{ type, message, timestamp }`          |
